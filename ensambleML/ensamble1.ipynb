{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "Ensemble learning in machine learning combines multiple individual models to create a stronger, more accurate predictive model. By leveraging the diverse strengths of different models, ensemble learning aims to mitigate errors, enhance performance, and increase the overall robustness of predictions, leading to improved results across various tasks in machine learning and data analysis.</br>\n",
    "\n",
    "[1] Ensemble Learning in Machine Learning: Stacking, Bagging and Boosting Mbali Kalirane https://www.analyticsvidhya.com/\n",
    "</font>\n",
    "\n",
    "<div>\n",
    "    <img src=\"img/Figure_1.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "<font size=3>\n",
    "When to use Bagging vs Boosting vs Stacking? \n",
    "</font>\n",
    "\n",
    "<div>\n",
    "    <img src=\"img/Figure_2.jpg\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "<font size=3>\n",
    "[2] Bagging vs Boosting vs Stacking in Machine Learning Amy https://grabngoinfo.com \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "# ensambles\n",
    "import xgboost\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# meta models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data https://www.kaggle.com/competitions/titanic/data\n",
    "\n",
    "data = pd.read_csv('data/train.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproces(data: pd.DataFrame):\n",
    "\n",
    "    # preprocess Age\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "    data[['Age']] = imputer.fit_transform(data[['Age']])\n",
    "\n",
    "    # preprocess Embarked\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "    data[['Embarked']] = imputer.fit_transform(data[['Embarked']])\n",
    "\n",
    "    data=data.drop(labels=['Cabin', 'PassengerId', 'Name'], axis=1)\n",
    "\n",
    "    # preprocess Tickets (LINE - value in one cell)\n",
    "    new_tickets = []\n",
    "\n",
    "    for i in data['Ticket']:\n",
    "        ii = i.split()\n",
    "        if ii == 'LINE':\n",
    "            ii = '0'\n",
    "        if len(ii) == 1:\n",
    "            new_tickets.append(ii[0])\n",
    "        elif len(ii) == 2:\n",
    "            new_tickets.append(ii[1])\n",
    "        elif len(ii) == 3:\n",
    "            new_tickets.append(ii[2])\n",
    "\n",
    "    data['Ticket'] = new_tickets\n",
    "\n",
    "    new_emb = pd.get_dummies(data=data['Embarked'], prefix='emb', prefix_sep='_')\n",
    "    new_sex = pd.get_dummies(data['Sex'], prefix='sex', prefix_sep='_')\n",
    "    data.drop(labels=['Embarked', 'Sex', 'Ticket'], axis=1, inplace=True)\n",
    "    data = pd.concat((data, new_emb, new_sex), axis=1)\n",
    "    #data = pd.concat((data, new_sex), axis=1) # without embarked\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess and split train data to train and validation subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preproces(data)\n",
    "\n",
    "y = data['Survived']\n",
    "X = data.drop(labels=['Survived'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check labels' balance\n",
    "\n",
    "d = collections.Counter(y)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 2))\n",
    "ax.bar(d.keys(), d.values())\n",
    "ax.set_xticks(ticks=list(d.keys()), labels=d.keys())\n",
    "ax.set_title('Balance in data\\' labels')\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Count of labels')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, \n",
    "                                                  y, \n",
    "                                                  train_size=0.8, \n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_val_sc = sc.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier (for train)\n",
      "accuracy: 0.98\n",
      "precission: 0.98\n",
      "recall: 0.97\n",
      "f1-score: 0.98\n",
      "Random Forest Classifier (for validation)\n",
      "accuracy: 0.80\n",
      "precission: 0.79\n",
      "recall: 0.79\n",
      "f1-score: 0.79\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "rfc = RandomForestClassifier(n_estimators=100,\n",
    "                             criterion='gini',\n",
    "                             max_depth=None,\n",
    "                             class_weight=None,\n",
    "                             verbose=False,\n",
    "                             n_jobs=-1)\n",
    "rfc.fit(X_train_sc, y_train)\n",
    "y_pred = rfc.predict(X_val_sc)\n",
    "\n",
    "# Metrics on train data\n",
    "\n",
    "y_pred_train = rfc.predict(X_train_sc)\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "precission, recall, f1, _ = precision_recall_fscore_support(y_train, y_pred_train, average='macro')\n",
    "\n",
    "print(f\"Random Forest Classifier (for train)\\naccuracy: {accuracy:.2f}\\nprecission: {precission:.2f}\\nrecall: {recall:.2f}\\nf1-score: {f1:.2f}\")\n",
    "\n",
    "y_pred_valid = rfc.predict(X_val_sc)\n",
    "accuracy = accuracy_score(y_val, y_pred_valid)\n",
    "precission, recall, f1, _ = precision_recall_fscore_support(y_val, y_pred_valid, average='macro')\n",
    "\n",
    "print(f\"\\nRandom Forest Classifier (for validation)\\naccuracy: {accuracy:.2f}\\nprecission: {precission:.2f}\\nrecall: {recall:.2f}\\nf1-score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier (for train)\n",
      "accuracy: 0.98\n",
      "precission: 0.98\n",
      "recall: 0.98\n",
      "f1-score: 0.98\n",
      "\n",
      "Random Forest Classifier (for validation)\n",
      "accuracy: 0.81\n",
      "precission: 0.80\n",
      "recall: 0.80\n",
      "f1-score: 0.80\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier with weighting\n",
    "\n",
    "w0 = len(y_train) / (len(np.unique(y_train)) * len(y_train[y_train==0]))\n",
    "w1 = len(y_train) / (len(np.unique(y_train)) * len(y_train[y_train==1]))\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100,\n",
    "                             criterion='gini',\n",
    "                             max_depth=None,\n",
    "                             class_weight={0:w0, 1:w1},\n",
    "                             verbose=False,\n",
    "                             n_jobs=-1)\n",
    "\n",
    "rfc.fit(X_train_sc, y_train)\n",
    "y_pred_train = rfc.predict(X_train_sc)\n",
    "y_pred_valid = rfc.predict(X_val_sc)\n",
    "\n",
    "# Metrics on train data\n",
    "\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "precission, recall, f1, _ = precision_recall_fscore_support(y_train, y_pred_train, average='macro')\n",
    "\n",
    "print(f\"Random Forest Classifier (for train)\\naccuracy: {accuracy:.2f}\\nprecission: {precission:.2f}\\nrecall: {recall:.2f}\\nf1-score: {f1:.2f}\")\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred_valid)\n",
    "precission, recall, f1, _ = precision_recall_fscore_support(y_val, y_pred_valid, average='macro')\n",
    "\n",
    "print(f\"\\nRandom Forest Classifier (for validation)\\naccuracy: {accuracy:.2f}\\nprecission: {precission:.2f}\\nrecall: {recall:.2f}\\nf1-score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging (Random Forest Classifier)\n",
    "\n",
    "<font size=3>\n",
    "<p>&emsp; 1. From n-elements training set choose m-subsets. Each subset is taken with replacement. Some data points can be sampled more than once.<p>\n",
    "<p>&emsp; 2. For each subset train weak learner independently. Learner are the same type. <p>\n",
    "<p>&emsp; 3. Each model make a prediction.<p>\n",
    "<p>&emsp; 4. Aggregation the predictions. Using max voting (for classification) or averaging (for regression) yeilds single prediction<p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging (Random Forest Classifier) (for train)\n",
      "accuracy: 0.94\n",
      "precission: 0.95\n",
      "recall: 0.93\n",
      "f1-score: 0.94\n",
      "\n",
      "Bagging (Random Forest Classifier) (for validation)\n",
      "accuracy: 0.84\n",
      "precission: 0.84\n",
      "recall: 0.83\n",
      "f1-score: 0.83\n"
     ]
    }
   ],
   "source": [
    "# for homogeneous estimators (hier rfc)\n",
    "# for high variance results\n",
    "\n",
    "bag = BaggingClassifier(estimator=rfc, n_estimators=100, max_samples=1.0,\n",
    "                        max_features=1.0, bootstrap=True,\n",
    "                        bootstrap_features=False,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "bag.fit(X_train_sc, y_train)\n",
    "y_pred_train = bag.predict(X_train_sc)\n",
    "y_pred_valid = bag.predict(X_val_sc)\n",
    "\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "precission, recall, f1, _ = precision_recall_fscore_support(y_train, y_pred_train, average='macro')\n",
    "\n",
    "print(f\"Bagging (Random Forest Classifier) (for train)\\naccuracy: {accuracy:.2f}\\nprecission: {precission:.2f}\\nrecall: {recall:.2f}\\nf1-score: {f1:.2f}\")\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred_valid)\n",
    "precission, recall, f1, _ = precision_recall_fscore_support(y_val, y_pred_valid, average='macro')\n",
    "\n",
    "print(f\"\\nBagging (Random Forest Classifier) (for validation)\\naccuracy: {accuracy:.2f}\\nprecission: {precission:.2f}\\nrecall: {recall:.2f}\\nf1-score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting (GradientBoostingClassifier)\n",
    "\n",
    "<font size=3>\n",
    "<p>&emsp; 1. From n-elements training set choose m-subsets. Each subset is taken with replacement. Some data points can be sampled more than once.<p>\n",
    "<p>&emsp; 2. Using first subset train first weak learner. <p>\n",
    "<p>&emsp; 3. Test using training data.<p>\n",
    "<p>&emsp; 4. All False predicted Data Points from 1st subset are send to 2nd subset.<p>\n",
    "<p>&emsp; 5. Using update 2nd subset train anather weak learner.<p>\n",
    "<p>&emsp; 6. Loop using above procedure until reach last subset.<p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier (Random Forest Classifier) (for train)\n",
      "accuracy: 0.93\n",
      "precission: 0.94\n",
      "recall: 0.91\n",
      "f1-score: 0.92\n",
      "\n",
      "Gradient Boosting Classifier (Random Forest Classifier) (for validation)\n",
      "accuracy: 0.82\n",
      "precission: 0.81\n",
      "recall: 0.80\n",
      "f1-score: 0.81\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators=200)\n",
    "\n",
    "gbc.fit(X_train_sc, y_train)\n",
    "y_pred_train = gbc.predict(X_train_sc)\n",
    "y_pred_valid = gbc.predict(X_val_sc)\n",
    "\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "precission, recall, f1, _ = precision_recall_fscore_support(y_train, y_pred_train, average='macro')\n",
    "\n",
    "print(f\"Gradient Boosting Classifier (Random Forest Classifier) (for train)\\naccuracy: {accuracy:.2f}\\nprecission: {precission:.2f}\\nrecall: {recall:.2f}\\nf1-score: {f1:.2f}\")\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred_valid)\n",
    "precission, recall, f1, _ = precision_recall_fscore_support(y_val, y_pred_valid, average='macro')\n",
    "\n",
    "print(f\"\\nGradient Boosting Classifier (Random Forest Classifier) (for validation)\\naccuracy: {accuracy:.2f}\\nprecission: {precission:.2f}\\nrecall: {recall:.2f}\\nf1-score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting (AdaBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier (Random Forest Classifier) (for train)\n",
      "accuracy: 0.98\n",
      "precission: 0.98\n",
      "recall: 0.98\n",
      "f1-score: 0.98\n",
      "\n",
      "AdaBoost Classifier (Random Forest Classifier) (for validation)\n",
      "accuracy: 0.82\n",
      "precission: 0.81\n",
      "recall: 0.81\n",
      "f1-score: 0.81\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(estimator=rfc, n_estimators=200)\n",
    "\n",
    "ada.fit(X_train_sc, y_train)\n",
    "y_pred_train = ada.predict(X_train_sc)\n",
    "y_pred_valid = ada.predict(X_val_sc)\n",
    "\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "precission, recall, f1, _ = precision_recall_fscore_support(y_train, y_pred_train, average='macro')\n",
    "\n",
    "print(f\"AdaBoost Classifier (Random Forest Classifier) (for train)\\naccuracy: {accuracy:.2f}\\nprecission: {precission:.2f}\\nrecall: {recall:.2f}\\nf1-score: {f1:.2f}\")\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred_valid)\n",
    "precission, recall, f1, _ = precision_recall_fscore_support(y_val, y_pred_valid, average='macro')\n",
    "\n",
    "print(f\"\\nAdaBoost Classifier (Random Forest Classifier) (for validation)\\naccuracy: {accuracy:.2f}\\nprecission: {precission:.2f}\\nrecall: {recall:.2f}\\nf1-score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosintg (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier (Random Forest Classifier) (for train)\n",
      "accuracy: 0.93\n",
      "precission: 0.94\n",
      "recall: 0.91\n",
      "f1-score: 0.92\n",
      "\n",
      "XGBoost Classifier (Random Forest Classifier) (for validation)\n",
      "accuracy: 0.81\n",
      "precission: 0.81\n",
      "recall: 0.80\n",
      "f1-score: 0.80\n"
     ]
    }
   ],
   "source": [
    "xgb = xgboost.XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "xgb.fit(X_train_sc, y_train)\n",
    "y_pred_train = xgb.predict(X_train_sc)\n",
    "y_pred_valid = xgb.predict(X_val_sc)\n",
    "\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "precission, recall, f1, _ = precision_recall_fscore_support(y_train, y_pred_train, average='macro')\n",
    "\n",
    "print(f\"XGBoost Classifier (Random Forest Classifier) (for train)\\naccuracy: {accuracy:.2f}\\nprecission: {precission:.2f}\\nrecall: {recall:.2f}\\nf1-score: {f1:.2f}\")\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred_valid)\n",
    "precission, recall, f1, _ = precision_recall_fscore_support(y_val, y_pred_valid, average='macro')\n",
    "\n",
    "print(f\"\\nXGBoost Classifier (Random Forest Classifier) (for validation)\\naccuracy: {accuracy:.2f}\\nprecission: {precission:.2f}\\nrecall: {recall:.2f}\\nf1-score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking (meta_model=LogisticRegression)\n",
    "\n",
    "<font size=3>\n",
    "<p>&emsp; 1. Use initial training data to train m-number algorithms.<p>\n",
    "<p>&emsp; 2. Using the output of each algorithm, create a new trainig set. <p>\n",
    "<p>&emsp; 3. Using the new training set create meta-model.<p>\n",
    "<p>&emsp; 4. Using the results of the meta-model make final prediction combining the result using weigthted averaging<p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn StackingClassifier (for train)\n",
      "accuracy: 0.94\n",
      "precission: 0.95\n",
      "recall: 0.92\n",
      "f1-score: 0.93\n",
      "\n",
      "sklearn StackingClassifier  (for validation)\n",
      "accuracy: 0.83\n",
      "precission: 0.83\n",
      "recall: 0.81\n",
      "f1-score: 0.82\n"
     ]
    }
   ],
   "source": [
    "base_models = [\n",
    "    ('rfc', RandomForestClassifier(n_estimators=100,\n",
    "                             criterion='gini',\n",
    "                             max_depth=None,\n",
    "                             class_weight={0:w0, 1:w1},\n",
    "                             verbose=False,\n",
    "                             n_jobs=-1)),                            \n",
    "    ('bag', BaggingClassifier(estimator=rfc, n_estimators=100, max_samples=1.0,\n",
    "                            max_features=1.0, bootstrap=True,\n",
    "                            bootstrap_features=False,\n",
    "                            n_jobs=-1)),         \n",
    "    ('gbc', GradientBoostingClassifier(n_estimators=200)),    \n",
    "    ('ada', AdaBoostClassifier(estimator=rfc, n_estimators=200)),\n",
    "    ('xgb', xgboost.XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42))\n",
    "]\n",
    "\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "stacking = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
    "stacking.fit(X_train_sc, y_train)\n",
    "y_pred_train = stacking.predict(X_train_sc)\n",
    "y_pred_valid = stacking.predict(X_val_sc)\n",
    "\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "precission, recall, f1, _ = precision_recall_fscore_support(y_train, y_pred_train, average='macro')\n",
    "\n",
    "print(f\"sklearn StackingClassifier (for train)\\naccuracy: {accuracy:.2f}\\nprecission: {precission:.2f}\\nrecall: {recall:.2f}\\nf1-score: {f1:.2f}\")\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred_valid)\n",
    "precission, recall, f1, _ = precision_recall_fscore_support(y_val, y_pred_valid, average='macro')\n",
    "\n",
    "print(f\"\\nsklearn StackingClassifier  (for validation)\\naccuracy: {accuracy:.2f}\\nprecission: {precission:.2f}\\nrecall: {recall:.2f}\\nf1-score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking (meta_model=SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn StackingClassifier (for train)\n",
      "accuracy: 0.92\n",
      "precission: 0.94\n",
      "recall: 0.90\n",
      "f1-score: 0.91\n",
      "\n",
      "sklearn StackingClassifier  (for validation)\n",
      "accuracy: 0.82\n",
      "precission: 0.82\n",
      "recall: 0.80\n",
      "f1-score: 0.80\n"
     ]
    }
   ],
   "source": [
    "base_models = [\n",
    "    ('rfc', RandomForestClassifier(n_estimators=100,\n",
    "                             criterion='gini',\n",
    "                             max_depth=None,\n",
    "                             class_weight={0:w0, 1:w1},\n",
    "                             verbose=False,\n",
    "                             n_jobs=-1)),                            \n",
    "    ('bag', BaggingClassifier(estimator=rfc, n_estimators=100, max_samples=1.0,\n",
    "                            max_features=1.0, bootstrap=True,\n",
    "                            bootstrap_features=False,\n",
    "                            n_jobs=-1)),         \n",
    "    ('gbc', GradientBoostingClassifier(n_estimators=200)),    \n",
    "    ('ada', AdaBoostClassifier(estimator=rfc, n_estimators=200)),\n",
    "    ('xgb', xgboost.XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42))\n",
    "]\n",
    "\n",
    "meta_model = SVC(gamma='auto')\n",
    "\n",
    "stacking = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
    "stacking.fit(X_train_sc, y_train)\n",
    "y_pred_train = stacking.predict(X_train_sc)\n",
    "y_pred_valid = stacking.predict(X_val_sc)\n",
    "\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "precission, recall, f1, _ = precision_recall_fscore_support(y_train, y_pred_train, average='macro')\n",
    "\n",
    "print(f\"sklearn StackingClassifier (for train)\\naccuracy: {accuracy:.2f}\\nprecission: {precission:.2f}\\nrecall: {recall:.2f}\\nf1-score: {f1:.2f}\")\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred_valid)\n",
    "precission, recall, f1, _ = precision_recall_fscore_support(y_val, y_pred_valid, average='macro')\n",
    "\n",
    "print(f\"\\nsklearn StackingClassifier  (for validation)\\naccuracy: {accuracy:.2f}\\nprecission: {precission:.2f}\\nrecall: {recall:.2f}\\nf1-score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model metrics\n",
      "accuracy: 0.80\n",
      "precission: 0.79\n",
      "recall: 0.78\n",
      "f1-score: 0.79\n",
      "\n",
      "Blending metrics\n",
      "accuracy: 0.76\n",
      "precission: 0.77\n",
      "recall: 0.74\n",
      "f1-score: 0.74\n"
     ]
    }
   ],
   "source": [
    "# define models\n",
    "\n",
    "def func_base_models():\n",
    "    models = list()\n",
    "    models.append(('rfc', RandomForestClassifier(n_estimators=150,\n",
    "                             criterion='gini',\n",
    "                             max_depth=None,\n",
    "                             class_weight={0:w0, 1:w1},\n",
    "                             verbose=False,\n",
    "                             n_jobs=-1))),                            \n",
    "    models.append(('bag', BaggingClassifier(estimator=rfc, n_estimators=150, max_samples=1.0,\n",
    "                            max_features=1.0, bootstrap=True,\n",
    "                            bootstrap_features=False,\n",
    "                            n_jobs=-1))),         \n",
    "    models.append(('gbc', GradientBoostingClassifier(n_estimators=150))),    \n",
    "    models.append(('ada', AdaBoostClassifier(estimator=rfc, n_estimators=150))),\n",
    "    models.append(('xgb', xgboost.XGBClassifier(n_estimators=200, learning_rate=0.1, random_state=42)))\n",
    "    \n",
    "    return models\n",
    "\n",
    "# 1. spliting dataset into train, validation, test set (X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "\n",
    "X_train_tmp, X_test, y_train_tmp, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_tmp, y_train_tmp, test_size=0.33, random_state=1)\n",
    "\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_val_sc = sc.transform(X_val)\n",
    "X_test_sc = sc.transform(X_test)\n",
    "\n",
    "# check metrics on base model \n",
    "\n",
    "base = LogisticRegression()\n",
    "# trainig base model and predictions of validatioin set\n",
    "base.fit(X_train_sc, y_train)\n",
    "yhat_base_valid = base.predict(X_val_sc)\n",
    "\n",
    "models = func_base_models()\n",
    "meta_X = list()\n",
    "\n",
    "# 2. train on train set and predict on validation set\n",
    "\n",
    "for name, model in models:\n",
    "    # training models on train set\n",
    "    model.fit(X_train_sc, y_train)\n",
    "\n",
    "    # predict on validation set\n",
    "    yhat_valid = model.predict_proba(X_val_sc)\n",
    "\n",
    "    # storing predictions\n",
    "    meta_X.append(yhat_valid)\n",
    "\n",
    "meta_X = np.hstack(meta_X)\n",
    "\n",
    "# 3. create blending meta learner\n",
    "\n",
    "blender = LogisticRegression()\n",
    "# trainig on base model predictions of validatioin set\n",
    "blender.fit(meta_X, y_val)\n",
    "\n",
    "# 4. do predictions using blending  meta learner\n",
    "\n",
    "meta_X = list()\n",
    "for name, model in models:\n",
    "  yhat = model.predict_proba(X_test.values)\n",
    "  meta_X.append(yhat)\n",
    "meta_X = np.hstack(meta_X)\n",
    "y_pred = blender.predict(meta_X)\n",
    "\n",
    "accuracy = accuracy_score(y_val, yhat_base_valid)\n",
    "precission, recall, f1, _ = precision_recall_fscore_support(y_val, yhat_base_valid, average='macro')\n",
    "\n",
    "print(f\"Base model metrics\\naccuracy: {accuracy:.2f}\\nprecission: {precission:.2f}\\nrecall: {recall:.2f}\\nf1-score: {f1:.2f}\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precission, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"\\nBlending metrics\\naccuracy: {accuracy:.2f}\\nprecission: {precission:.2f}\\nrecall: {recall:.2f}\\nf1-score: {f1:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
